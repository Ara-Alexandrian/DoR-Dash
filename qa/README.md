# DoR-Dash Quality Assurance (QA) Directory

This directory contains all quality assurance reports, testing scripts, and documentation for the DoR-Dash system.

## Directory Structure

```
qa/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ LLM-QA/               # LLM text refinement QA reports
â”‚   â””â”€â”€ llm_qa_report_*.md # Timestamped LLM test reports
â”œâ”€â”€ Validation/           # General validation reports
â”‚   â””â”€â”€ QA_Validation_*.md # System validation reports
â”œâ”€â”€ database/             # Database testing and verification scripts
â”‚   â”œâ”€â”€ check_db_state.py # Check current database state
â”‚   â””â”€â”€ init_test_data.py # Initialize test data
â”œâ”€â”€ integration/          # Integration tests
â”‚   â””â”€â”€ api_tests.py      # API endpoint integration tests
â””â”€â”€ utils/                # Testing utilities
    â””â”€â”€ ssh_runner.py     # Utility to run tests on deployed container
```

## Report Types

### ğŸ“ LLM-QA Reports (`qa/LLM-QA/`)

**Purpose**: Validate that the LLM text refinement system behaves conservatively and produces expected outputs.

**Generated by**: `/api/v1/text-testing/run-tests` endpoint  
**Frequency**: On-demand when testing LLM behavior  
**Format**: Markdown files with timestamped filenames  

**Contents**:
- Test case results with input/output comparisons
- Length expansion analysis
- Conservative behavior validation
- Pass/fail status for each test
- Recommendations for improvements

**Naming Convention**: `llm_qa_report_YYYYMMDD_HHMMSS.md`

### ğŸ” Validation Reports (`qa/Validation/`)

**Purpose**: General system validation and QA_Validation reports.

**Generated by**: Various validation processes  
**Frequency**: As needed during development and deployment  
**Format**: Markdown files with descriptive names  

**Contents**:
- System functionality validation
- Performance testing results
- Integration testing reports
- Deployment validation

**Naming Convention**: `QA_Validation_[description]_YYYYMMDD.md`

## Usage

### Running LLM QA Tests

```bash
# Via API (admin users only)
curl -X POST "http://your-server/api/v1/text-testing/run-tests" \
  -H "Authorization: Bearer YOUR_TOKEN"

# Response includes report location
{
  "summary": {...},
  "results": [...],
  "qa_report": {
    "generated": true,
    "location": "/config/workspace/gitea/DoR-Dash/qa/LLM-QA/llm_qa_report_20250616_212000.md",
    "timestamp": "2025-06-16T21:20:00.123456"
  }
}
```

### Check Database State
```bash
python qa/database/check_db_state.py
```

### Run Integration Tests
```bash
python qa/integration/api_tests.py
```

### Viewing Test Cases

```bash
# Get all available test cases
curl -X GET "http://your-server/api/v1/text-testing/test-cases" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## Best Practices

1. **Regular Testing**: Run LLM QA tests after any changes to:
   - LLM prompts or model parameters
   - Text refinement logic
   - Model upgrades

2. **Report Review**: Always review generated reports for:
   - Unexpected failures
   - Length expansion issues
   - Unwanted formatting (emojis, dramatic headers)
   - Degraded conservative behavior

3. **Version Control**: All QA reports are tracked in git to maintain:
   - Historical test results
   - Regression detection
   - Performance trends over time

4. **Documentation**: Update this README when:
   - Adding new test types
   - Changing report formats
   - Modifying QA processes

## Testing Hierarchy

- **Unit Tests**: Located in `backend/tests/` for individual component testing
- **Integration Tests**: Located in `qa/integration/` for full-stack verification
- **LLM QA Tests**: Automated via API endpoints with report generation
- **Manual QA**: Documented validation reports in `qa/Validation/`

## Troubleshooting

### Common Issues

**LLM Tests Failing**:
- Check Ollama service availability at `172.30.98.14:11434`
- Verify Gemma 3 4B model is loaded
- Review failed test details in the generated report

**Report Generation Errors**:
- Ensure write permissions to `qa/` directory
- Check disk space availability
- Verify file system accessibility

**Authentication Issues**:
- LLM testing endpoints require admin/faculty role
- Ensure valid authentication token
- Check user permissions in the system

## Contact

For questions about QA processes or report interpretation, contact the development team or refer to the main project documentation.