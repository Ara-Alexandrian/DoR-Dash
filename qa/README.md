# DoR-Dash Quality Assurance (QA) Directory

This directory contains all quality assurance reports, testing scripts, and documentation for the DoR-Dash system.

## Directory Structure

```
qa/
├── README.md              # This file
├── LLM-QA/               # LLM text refinement QA reports
│   └── llm_qa_report_*.md # Timestamped LLM test reports
├── Validation/           # General validation reports
│   └── QA_Validation_*.md # System validation reports
├── database/             # Database testing and verification scripts
│   ├── check_db_state.py # Check current database state
│   └── init_test_data.py # Initialize test data
├── integration/          # Integration tests
│   └── api_tests.py      # API endpoint integration tests
└── utils/                # Testing utilities
    └── ssh_runner.py     # Utility to run tests on deployed container
```

## Report Types

### 📝 LLM-QA Reports (`qa/LLM-QA/`)

**Purpose**: Validate that the LLM text refinement system behaves conservatively and produces expected outputs.

**Generated by**: `/api/v1/text-testing/run-tests` endpoint  
**Frequency**: On-demand when testing LLM behavior  
**Format**: Markdown files with timestamped filenames  

**Contents**:
- Test case results with input/output comparisons
- Length expansion analysis
- Conservative behavior validation
- Pass/fail status for each test
- Recommendations for improvements

**Naming Convention**: `llm_qa_report_YYYYMMDD_HHMMSS.md`

### 🔍 Validation Reports (`qa/Validation/`)

**Purpose**: General system validation and QA_Validation reports.

**Generated by**: Various validation processes  
**Frequency**: As needed during development and deployment  
**Format**: Markdown files with descriptive names  

**Contents**:
- System functionality validation
- Performance testing results
- Integration testing reports
- Deployment validation

**Naming Convention**: `QA_Validation_[description]_YYYYMMDD.md`

## Usage

### Running LLM QA Tests

```bash
# Via API (admin users only)
curl -X POST "http://your-server/api/v1/text-testing/run-tests" \
  -H "Authorization: Bearer YOUR_TOKEN"

# Response includes report location
{
  "summary": {...},
  "results": [...],
  "qa_report": {
    "generated": true,
    "location": "/config/workspace/gitea/DoR-Dash/qa/LLM-QA/llm_qa_report_20250616_212000.md",
    "timestamp": "2025-06-16T21:20:00.123456"
  }
}
```

### Check Database State
```bash
python qa/database/check_db_state.py
```

### Run Integration Tests
```bash
python qa/integration/api_tests.py
```

### Viewing Test Cases

```bash
# Get all available test cases
curl -X GET "http://your-server/api/v1/text-testing/test-cases" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## Best Practices

1. **Regular Testing**: Run LLM QA tests after any changes to:
   - LLM prompts or model parameters
   - Text refinement logic
   - Model upgrades

2. **Report Review**: Always review generated reports for:
   - Unexpected failures
   - Length expansion issues
   - Unwanted formatting (emojis, dramatic headers)
   - Degraded conservative behavior

3. **Version Control**: All QA reports are tracked in git to maintain:
   - Historical test results
   - Regression detection
   - Performance trends over time

4. **Documentation**: Update this README when:
   - Adding new test types
   - Changing report formats
   - Modifying QA processes

## Testing Hierarchy

- **Unit Tests**: Located in `backend/tests/` for individual component testing
- **Integration Tests**: Located in `qa/integration/` for full-stack verification
- **LLM QA Tests**: Automated via API endpoints with report generation
- **Manual QA**: Documented validation reports in `qa/Validation/`

## Troubleshooting

### Common Issues

**LLM Tests Failing**:
- Check Ollama service availability at `172.30.98.14:11434`
- Verify Gemma 3 4B model is loaded
- Review failed test details in the generated report

**Report Generation Errors**:
- Ensure write permissions to `qa/` directory
- Check disk space availability
- Verify file system accessibility

**Authentication Issues**:
- LLM testing endpoints require admin/faculty role
- Ensure valid authentication token
- Check user permissions in the system

## Contact

For questions about QA processes or report interpretation, contact the development team or refer to the main project documentation.